{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## This script links the flood sum map that was generated in GEE to the corresponding flood frequenices \n",
    "## for the Prek Area \n",
    "## ex√ºprted from this script: https://code.earthengine.google.com/f69af6afbec2c0a5d43a173a965c67be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import math\n",
    "from matplotlib.dates import date2num\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_KK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-09-05</th>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-06</th>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-07</th>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-08</th>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-09</th>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wl_KK\n",
       "date             \n",
       "1990-09-05   7.16\n",
       "1990-09-06   7.20\n",
       "1990-09-07   7.22\n",
       "1990-09-08   7.22\n",
       "1990-09-09   7.21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# water level at Koh Kehl \n",
    "\n",
    "wl_long = pd.read_csv('wl_KK.csv')\n",
    "wl_long['date'] = pd.to_datetime(wl_long['date'])\n",
    "wl_long['date'] = wl_long['date'].dt.strftime('%Y-%m-%d')\n",
    "wl_long.columns = ['huh', 'date', 'wl_long']\n",
    "wl_long = wl_long.drop(columns=['huh'])\n",
    "wl_long = wl_long.set_index('date')\n",
    "wl_long['wl_long'] = wl_long['wl_long']-1 # <------ -1 correct for elevation \n",
    "\n",
    "# for data availability comparison:\n",
    "wl_long.index = pd.to_datetime(wl_long.index)\n",
    "wl_long1 = wl_long.resample('d').max()\n",
    "\n",
    "wl_KK_daily = wl_long1  \n",
    "wl_KK_daily.columns = ['wl_KK']\n",
    "wl_original = wl_KK_daily\n",
    "\n",
    "#wl_KK_daily = wl_KK_daily.rolling(center=False, window=3, min_periods=1).mean().round(2)\n",
    "\n",
    "#wl_KK_daily.to_csv('wl_KK_smoothed.csv')\n",
    "\n",
    "wl_KK_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_KK</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentinel_date_PA</th>\n",
       "      <th>Sentinel_date_2C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-09-05</th>\n",
       "      <td>7.16</td>\n",
       "      <td>1990-09-05</td>\n",
       "      <td>1990-09-17</td>\n",
       "      <td>1990-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-06</th>\n",
       "      <td>7.20</td>\n",
       "      <td>1990-09-06</td>\n",
       "      <td>1990-09-18</td>\n",
       "      <td>1990-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-07</th>\n",
       "      <td>7.22</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>1990-09-19</td>\n",
       "      <td>1990-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-08</th>\n",
       "      <td>7.22</td>\n",
       "      <td>1990-09-08</td>\n",
       "      <td>1990-09-20</td>\n",
       "      <td>1990-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-09-09</th>\n",
       "      <td>7.21</td>\n",
       "      <td>1990-09-09</td>\n",
       "      <td>1990-09-21</td>\n",
       "      <td>1990-10-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wl_KK       date Sentinel_date_PA Sentinel_date_2C\n",
       "date                                                          \n",
       "1990-09-05   7.16 1990-09-05       1990-09-17       1990-10-01\n",
       "1990-09-06   7.20 1990-09-06       1990-09-18       1990-10-02\n",
       "1990-09-07   7.22 1990-09-07       1990-09-19       1990-10-03\n",
       "1990-09-08   7.22 1990-09-08       1990-09-20       1990-10-04\n",
       "1990-09-09   7.21 1990-09-09       1990-09-21       1990-10-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SIMPLE: calculate fixed shifts! \n",
    "wl_KK_daily['date'] = wl_KK_daily.index\n",
    "wl_KK_daily['Sentinel_date_PA'] = wl_KK_daily['date'].shift(-12)\n",
    "wl_KK_daily['Sentinel_date_2C'] = wl_KK_daily['date'].shift(-26)\n",
    "\n",
    "wl_KK_daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-09-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-07</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2016-09-29, 2017-08-14, 2019-09-24, 2011-10-14, 2000-10-07]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### import list of dates manually generated \n",
    "\n",
    "dates_simple = pd.read_csv('IE_PA_Simple.csv')\n",
    "dates_simple['Date'] = pd.to_datetime(dates_simple['Date'])\n",
    "dates_simple['Date'] = dates_simple['Date'].dt.strftime('%Y-%m-%d')\n",
    "dates_simple['date'] = dates_simple['Date']\n",
    "\n",
    "dates_simple = dates_simple.set_index('date')\n",
    "\n",
    "df = dates_simple.drop(columns='Date')\n",
    "\n",
    "\n",
    "df.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_KK</th>\n",
       "      <th>date</th>\n",
       "      <th>count_reached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.90</td>\n",
       "      <td>2000-09-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.88</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.82</td>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.70</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.68</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wl_KK       date  count_reached\n",
       "1   6.90 2000-09-25              1\n",
       "2   6.88 2011-10-02              2\n",
       "3   6.82 2018-09-03              3\n",
       "4   6.70 2018-09-13              4\n",
       "5   6.68 2019-09-12              5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### match them to the water levels at KK at the correct date\n",
    "\n",
    "wl_KK_PA = wl_KK_daily\n",
    "\n",
    "wl_KK_PA = wl_KK_PA.set_index('Sentinel_date_PA') # set the PA date to index\n",
    "\n",
    "#wl_KK_PA = wl_KK_PA.sort_values('wl_KK') # sort by water level (ascending)\n",
    "\n",
    "wl_KK_PA = wl_KK_PA[~wl_KK_PA.index.duplicated(keep='first')] # get rid of duplicates\n",
    "\n",
    "flood_link = df.merge(wl_KK_PA, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "flood_link = flood_link.drop(columns=['Sentinel_date_2C'])\n",
    "\n",
    "flood_link = flood_link.sort_values('wl_KK',ascending=False)\n",
    "\n",
    "#flood_link['image_date'] = flood_link.index\n",
    "\n",
    "flood_link.index = np.arange(1, len(flood_link) + 1)\n",
    "\n",
    "flood_link['count_reached'] = flood_link.index\n",
    "\n",
    "flood_link_original = flood_link\n",
    "\n",
    "flood_link.head()\n",
    "wl_KK_PA.head()\n",
    "\n",
    "\n",
    "flood_link.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_original['date'] = wl_original.index\n",
    "wl_original['date'] = pd.to_datetime(wl_original['date'])\n",
    "wl_original['monthday'] = wl_original['date'].dt.strftime('%m-%d')\n",
    "wl_original['year'] = wl_original['date'].dt.strftime('%Y')\n",
    "\n",
    "### define function that counts how many times in this time range, \n",
    "### a certain value was exceeded by the test date! \n",
    "\n",
    "def counting_times_reached(wl):\n",
    "        list1 = []\n",
    "        for year in years: \n",
    "            year = str(year)\n",
    "            wl_year = wl_original[(wl_original['year']==year)] # filter for year \n",
    "            wl_decide = wl_year[(wl_year['monthday']<=testdate)] # filter before date\n",
    "            #wl_min = wl_decide1['wl_long'].min()\n",
    "            #date_min = wl_decide1[(wl_decide1.wl_long==wl_min).idxmax()]['date']  \n",
    "            #wl_decide = wl_decide1[(wl_decide1['date'] > date_min)] # after dry season min\n",
    "            check = (wl_decide['wl_KK'] >= wl).any()#.astype(int) # check if present\n",
    "            list1.append(check)\n",
    "        total_sum = float(sum(list1))/float(len(years))\n",
    "        return total_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1991' '1992' '1993' '1994' '1995' '1996' '1997' '1998' '1999' '2000']\n",
      "['2001' '2002' '2003' '2004' '2005' '2006' '2007' '2008' '2009' '2010']\n",
      "['2011' '2012' '2013' '2014' '2015' '2016' '2017' '2018' '2019' '2020']\n"
     ]
    }
   ],
   "source": [
    "wl_90s = wl_original[(wl_original['year']<='2000')& (wl_original['year']>'1990')]\n",
    "wl_00s = wl_original[(wl_original['year']>'2000')&(wl_original['year']<='2010')]\n",
    "wl_10s = wl_original[(wl_original['year'] > '2010') & (wl_original['year']<='2020')\n",
    "                    \n",
    "                    ]\n",
    "wl_pre08 = wl_original[(wl_original['year'] <= '2008')]\n",
    "wl_post08 = wl_original[(wl_original['year'] > '2008')]\n",
    "\n",
    "years1 = wl_90s.year.unique()\n",
    "years2 = wl_00s.year.unique()\n",
    "years3 = wl_10s.year.unique()\n",
    "\n",
    "print(years1)\n",
    "print(years2)\n",
    "print(years3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the OVERALL time period 1990-2021\n",
    "\n",
    "years = wl_original.year.unique()\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_overall')\n",
    "\n",
    "### split into lookup tables \n",
    "\n",
    "### water level \n",
    "\n",
    "SPA_OA_wl = pd.DataFrame()\n",
    "\n",
    "SPA_OA_wl['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_wl['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_wl['Value'] = flood_link['wl_KK'].astype(float)\n",
    "\n",
    "SPA_OA_wl.to_excel('SPA_OA_wl.xlsx', index=False)\n",
    "\n",
    "#### overall \n",
    "\n",
    "SPA_OA_OA = pd.DataFrame()\n",
    "\n",
    "SPA_OA_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_OA_OA.to_excel('SPA_OA_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_OA_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_OA_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_OA_J15.to_excel('SPA_OA_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_OA_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_OA_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_OA_J31.to_excel('SPA_OA_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_OA_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_OA_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_OA_A15.to_excel('SPA_OA_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_OA_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_OA_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_OA_A31.to_excel('SPA_OA_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_OA_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_OA_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_OA_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_OA_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_OA_S25.to_excel('SPA_OA_S25.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the OVERALL time period 1990-2021\n",
    "\n",
    "years = wl_90s.year.unique()\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_90s')\n",
    "\n",
    "### split into lookup tables \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### overall \n",
    "\n",
    "SPA_90s_OA = pd.DataFrame()\n",
    "\n",
    "SPA_90s_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_90s_OA.to_excel('SPA_90s_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_90s_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_90s_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_90s_J15.to_excel('SPA_90s_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_90s_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_90s_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_90s_J31.to_excel('SPA_90s_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_90s_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_90s_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_90s_A15.to_excel('SPA_90s_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_90s_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_90s_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_90s_A31.to_excel('SPA_90s_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_90s_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_90s_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_90s_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_90s_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_90s_S25.to_excel('SPA_90s_S25.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the 00s time period 1990-2021\n",
    "\n",
    "years = wl_00s.year.unique()\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_00s')\n",
    "### split into lookup tables \n",
    "\n",
    "\n",
    "\n",
    "### overall \n",
    "\n",
    "SPA_00s_OA = pd.DataFrame()\n",
    "\n",
    "SPA_00s_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_00s_OA.to_excel('SPA_00s_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_00s_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_00s_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_00s_J15.to_excel('SPA_00s_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_00s_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_00s_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_00s_J31.to_excel('SPA_00s_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_00s_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_00s_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_00s_A15.to_excel('SPA_00s_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_00s_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_00s_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_00s_A31.to_excel('SPA_00s_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_00s_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_00s_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_00s_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_00s_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_00s_S25.to_excel('SPA_00s_S25.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the OVERALL time period 1990-2021\n",
    "\n",
    "years = wl_10s.year.unique()\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_10s')\n",
    "\n",
    "### split into lookup tables \n",
    "\n",
    "\n",
    "\n",
    "#### overall\n",
    "\n",
    "SPA_10s_OA = pd.DataFrame()\n",
    "\n",
    "SPA_10s_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_10s_OA.to_excel('SPA_10s_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_10s_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_10s_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_10s_J15.to_excel('SPA_10s_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_10s_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_10s_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_10s_J31.to_excel('SPA_10s_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_10s_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_10s_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_10s_A15.to_excel('SPA_10s_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_10s_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_10s_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_10s_A31.to_excel('SPA_10s_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_10s_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_10s_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_10s_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_10s_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_10s_S25.to_excel('SPA_10s_S25.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the OVERALL time period 1990-2021\n",
    "\n",
    "years = wl_pre08.year.unique()\n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_pre08')\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "\n",
    "\n",
    "### split into lookup tables \n",
    "\n",
    "\n",
    "\n",
    "#### overall\n",
    "\n",
    "SPA_pre08_OA = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_pre08_OA.to_excel('SPA_pre08_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_pre08_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_pre08_J15.to_excel('SPA_pre08_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_pre08_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_pre08_J31.to_excel('SPA_pre08_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_pre08_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_pre08_A15.to_excel('SPA_pre08_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_pre08_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_pre08_A31.to_excel('SPA_pre08_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_pre08_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_pre08_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_pre08_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_pre08_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_pre08_S25.to_excel('SPA_pre08_S25.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### implement the function for the OVERALL time period 1990-2021\n",
    "\n",
    "years = wl_post08.year.unique()\n",
    "\n",
    "testdate = '11-31'\n",
    "flood_link['freq_overall'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-15'\n",
    "flood_link['freq_Jul15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years\n",
    "\n",
    "testdate = '07-31'\n",
    "flood_link['freq_Jul31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-15'\n",
    "flood_link['freq_Aug15'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '08-31'\n",
    "flood_link['freq_Aug31'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "testdate = '09-15'\n",
    "flood_link['freq_Sep25'] = (flood_link['wl_KK'].apply(counting_times_reached))#/number_years \n",
    "\n",
    "\n",
    "flood_link.to_csv('flood_link_GEE_SPA_post08')\n",
    "### split into lookup tables \n",
    "\n",
    "\n",
    "\n",
    "#### overall\n",
    "\n",
    "SPA_post08_OA = pd.DataFrame()\n",
    "\n",
    "SPA_post08_OA['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_OA['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_OA['Value'] = flood_link['freq_overall'].astype(float)\n",
    "\n",
    "SPA_post08_OA.to_excel('SPA_post08_OA.xlsx', index=False)\n",
    "\n",
    "\n",
    "##### July 15 \n",
    "SPA_post08_J15 = pd.DataFrame()\n",
    "\n",
    "SPA_post08_J15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_J15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_J15['Value'] = flood_link['freq_Jul15'].astype(float)\n",
    "\n",
    "SPA_post08_J15.to_excel('SPA_post08_J15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### July 31\n",
    "\n",
    "SPA_post08_J31 = pd.DataFrame()\n",
    "\n",
    "SPA_post08_J31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_J31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_J31['Value'] = flood_link['freq_Jul31'].astype(float)\n",
    "\n",
    "SPA_post08_J31.to_excel('SPA_post08_J31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 15 \n",
    "SPA_post08_A15 = pd.DataFrame()\n",
    "\n",
    "SPA_post08_A15['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_A15['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_A15['Value'] = flood_link['freq_Aug15'].astype(float)\n",
    "\n",
    "SPA_post08_A15.to_excel('SPA_post08_A15.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Aug 31\n",
    "SPA_post08_A31 = pd.DataFrame()\n",
    "\n",
    "SPA_post08_A31['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_A31['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_A31['Value'] = flood_link['freq_Aug31'].astype(float)\n",
    "\n",
    "SPA_post08_A31.to_excel('SPA_post08_A31.xlsx', index=False)\n",
    "\n",
    "\n",
    "#### Sep 25\n",
    "\n",
    "SPA_post08_S25 = pd.DataFrame()\n",
    "\n",
    "SPA_post08_S25['Minimum'] = (flood_link['count_reached']-0.0002).astype(float)\n",
    "SPA_post08_S25['Maximum'] = (flood_link['count_reached']+0.0002).astype(float)\n",
    "SPA_post08_S25['Value'] = flood_link['freq_Sep25'].astype(float)\n",
    "\n",
    "SPA_post08_S25.to_excel('SPA_post08_S25.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_inundation_duration(i): \n",
    "    \n",
    "    ### make empty list \n",
    "    list1 = []\n",
    "    \n",
    "    ### get average duration for each year \n",
    "    \n",
    "    for y in years: \n",
    "\n",
    "            #######\n",
    "            # Get the wet season / dry season duration for year n & n+1 \n",
    "            #######\n",
    "            \n",
    "            # cut to year y \n",
    "            wlnew = wl_original[(wl_original['year'] == y)] \n",
    "            \n",
    "            # get minimum water level (height of dry season)\n",
    "            wl_min = wlnew['wl_KK'].min() \n",
    "            \n",
    "            # find the date that was reached \n",
    "            date_min = wlnew.loc[(wlnew.wl_KK==wl_min).idxmax()]['date']  # get date of miimum level\n",
    "           \n",
    "            # cut the series to after that date \n",
    "            wl_new_1 = wlnew[(wlnew['date']> date_min)] # cut to after the peak of the dry season \n",
    "            \n",
    "\n",
    "\n",
    "            #######\n",
    "            # Find the end of the dry season in the subsequent year \n",
    "            #######\n",
    "\n",
    "\n",
    "            ### get the series for the subsequent year \n",
    "            \n",
    "            # get subsequent year \n",
    "            year_n1 = int(y)+1\n",
    "            year_n1 = str(year_n1)\n",
    "            wl_yn1 = wl_original[(wl_original['year'] == year_n1)]\n",
    "            \n",
    "            # find minimum level that year \n",
    "            wl_min = wl_yn1['wl_KK'].min()\n",
    "            \n",
    "            # get date of minimum level \n",
    "            date_min = wl_yn1.loc[(wl_yn1.wl_KK==wl_min).idxmax()]['date']  \n",
    "            \n",
    "            # cut to before that date \n",
    "            wl_new_2 = wl_yn1[(wl_yn1['date'] <= date_min)]\n",
    "            \n",
    "\n",
    "            ## concatenate \n",
    "\n",
    "            wl_filter = pd.concat([wl_new_2, wl_new_1], axis=0)\n",
    "\n",
    "            \n",
    "\n",
    "            #######\n",
    "            # threshold for the dates when the wl was above! \n",
    "            #######\n",
    "\n",
    "\n",
    "            wl_above = wl_filter[(wl_filter['wl_KK'])>= i]\n",
    "            \n",
    "            wl_above_nr = len(wl_above.index)\n",
    "            \n",
    "            ## append to list \n",
    "            \n",
    "            list1.append(wl_above_nr)\n",
    "            \n",
    "\n",
    "    average_duration = float(sum(list1))/float(len(years))\n",
    "        \n",
    "    return average_duration \n",
    "\n",
    "###### calculate average flood durations for all water levels for each decade \n",
    "\n",
    "\n",
    "duration_link = flood_link_original.drop(columns=['date', 'freq_overall', 'freq_Jul15', 'freq_Jul31', 'freq_Aug15', 'freq_Aug31', 'freq_Sep25'])\n",
    "\n",
    "#duration_link = duration_link.set_index('wl_KK')\n",
    "\n",
    "years = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "duration_link['overall'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "years = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000']\n",
    "duration_link['90s'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "years = ['2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010']\n",
    "duration_link['00s'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "years = ['2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "duration_link['10s'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "years = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008']\n",
    "duration_link['pre08'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "years = ['2009', '2010','2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "duration_link['post08'] = duration_link['wl_KK'].apply(average_inundation_duration)\n",
    "\n",
    "\n",
    "duration_link.head(31)\n",
    "\n",
    "duration_link.to_excel('SPA_flood_duration.xlsx', index=False)\n",
    "duration_link.to_csv('SPA_flood_duration.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
